{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Digit Recognition via CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNafVLW+UzfVfDdqBwEpxbL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EGanji/DLMLprojects/blob/main/MNIST_Digit_Recognition_via_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Digit Recognition through Convolutional Neural Network\n",
        "* Goal: Build a network and train it to recognize handwritten digits.\n",
        "* Data set: MNIST\n",
        "* Metric: Accuracy\n",
        "\n",
        "#### Outline:\n",
        "0. Install/import required libraries.\n",
        "1. Loading data -> train and test set\n",
        "2. Visualize data, get familiar with data\n",
        "3. Preprocessing -> \n",
        "  * Normalizing data\n",
        "  * Convert Labels into one-hot vectors.\n",
        "4. Building the Model\n",
        "5. Train the Model\n",
        "6. Evaluate the Model's Accuracy\n",
        "7. Inspection output\n",
        "8. Final Notes"
      ],
      "metadata": {
        "id": "60Nqc1e1kq1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "bk4SHYLRmoHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random                        # for generating random numbers\n",
        "\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.utils import np_utils                         # NumPy related tools"
      ],
      "metadata": {
        "id": "_8vjpT1bmoD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2SFOoTYkokC"
      },
      "outputs": [],
      "source": [
        "# import some additional tools\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n",
        "from keras.layers.normalization import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "-QwfoS99lE-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Again, do some formatting\n",
        "# Except we do not flatten each image into a 784-length vector because we want to perform convolutions first\n",
        "\n",
        "X_train = X_train.reshape(60000, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_test /= 255\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ],
      "metadata": {
        "id": "mjGivvOLlHr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot format classes\n",
        "\n",
        "nb_classes = 10 # number of unique digits\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "metadata": {
        "id": "ZxzFMt84lJgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the Deep CNN"
      ],
      "metadata": {
        "id": "cgRt6mxKmKfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()                                 # Linear stacking of layers\n",
        "\n",
        "# Convolution Layer 1\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "convLayer01 = Activation('relu')                     # activation\n",
        "model.add(convLayer01)\n",
        "\n",
        "# Convolution Layer 2\n",
        "model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "model.add(Activation('relu'))                        # activation\n",
        "convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "model.add(convLayer02)\n",
        "\n",
        "# Convolution Layer 3\n",
        "model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "convLayer03 = Activation('relu')                     # activation\n",
        "model.add(convLayer03)\n",
        "\n",
        "# Convolution Layer 4\n",
        "model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "model.add(Activation('relu'))                        # activation\n",
        "convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "model.add(convLayer04)\n",
        "model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
        "\n",
        "# Fully Connected Layer 5\n",
        "model.add(Dense(512))                                # 512 FCN nodes\n",
        "model.add(BatchNormalization())                      # normalization\n",
        "model.add(Activation('relu'))                        # activation\n",
        "\n",
        "# Fully Connected Layer 6                       \n",
        "model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n",
        "model.add(Dense(10))                                 # final 10 FCN nodes\n",
        "model.add(Activation('softmax'))                     # softmax activation"
      ],
      "metadata": {
        "id": "lQ0e_ViqlPQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "QkCjEQgxlTGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we'll use the same optimizer\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hk1eSZfQlVgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data augmentation prevents overfitting by slightly changing the data randomly\n",
        "# Keras has a great built-in feature to do automatic augmentation\n",
        "\n",
        "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
        "                         height_shift_range=0.08, zoom_range=0.08)\n",
        "\n",
        "test_gen = ImageDataGenerator()"
      ],
      "metadata": {
        "id": "B7PnMICPlZI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can then feed our augmented data in batches\n",
        "# Besides loss function considerations as before, this method actually results in significant memory savings\n",
        "# because we are actually LOADING the data into the network in batches before processing each batch\n",
        "\n",
        "# Before the data was all loaded into memory, but then processed in batches.\n",
        "\n",
        "train_generator = gen.flow(X_train, Y_train, batch_size=128)\n",
        "test_generator = test_gen.flow(X_test, Y_test, batch_size=128)"
      ],
      "metadata": {
        "id": "MpKclmVclZ-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can now train our model which is fed data by our batch loader\n",
        "# Steps per epoch should always be total size of the set divided by the batch size\n",
        "\n",
        "# SIGNIFICANT MEMORY SAVINGS (important for larger, deeper networks)\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=60000//128, epochs=5, verbose=1, \n",
        "                    validation_data=test_generator, validation_steps=10000//128)"
      ],
      "metadata": {
        "id": "8B7mGpP-lcRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "c5wYYOh_ld-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But wouldn't it be nice if we could visualize those convolutions so that we can see what the model is seeing?"
      ],
      "metadata": {
        "id": "g3giJiuZlmOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "# choose any image to want by specifying the index\n",
        "img = X_test[3]\n",
        "img = np.expand_dims(img, axis=0) # Keras requires the image to be in 4D, so we add an extra dimension to it.\n",
        "\n",
        "# Not important to understand how this function work -- It just plots a convolution layer\n",
        "\n",
        "def visualize(layer):\n",
        "    inputs = [K.learning_phase()] + model.inputs\n",
        "    \n",
        "    _convout1_f = K.function(inputs, [layer.output])\n",
        "    \n",
        "    def convout1_f(X):\n",
        "        # The [0] is to disable the training phase flag\n",
        "        return _convout1_f([0] + [X])\n",
        "\n",
        "    convolutions = convout1_f(img)\n",
        "    convolutions = np.squeeze(convolutions)\n",
        "\n",
        "    print ('Shape of conv:', convolutions.shape)\n",
        "    \n",
        "    m = convolutions.shape[2]\n",
        "    n = int(np.ceil(np.sqrt(m)))\n",
        "    \n",
        "    # Visualization of each filter of the layer\n",
        "    fig = plt.figure(figsize=(15,12))\n",
        "    for i in range(m):\n",
        "        ax = fig.add_subplot(n,n,i+1)\n",
        "        ax.imshow(convolutions[:,:,i], cmap='gray')"
      ],
      "metadata": {
        "id": "pXRzfI_2lku4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(X_test[3].reshape(28,28), cmap='gray', interpolation='none')"
      ],
      "metadata": {
        "id": "Egf5AbajlkoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(convLayer01) # visualize first set of feature maps"
      ],
      "metadata": {
        "id": "zTOCFQMPlkTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(convLayer02) # visualize second set of feature maps"
      ],
      "metadata": {
        "id": "4nohUYzmlqYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(convLayer03)# visualize third set of feature maps"
      ],
      "metadata": {
        "id": "5hX1OneDlqP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(convLayer04)# visualize fourth set of feature maps"
      ],
      "metadata": {
        "id": "7nPrKaKplqK4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}